{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. ALS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b6fshnqIlfLd"},"source":["# Topic 3: Recommender System"]},{"cell_type":"markdown","metadata":{"id":"gRP78FBKlfIc"},"source":["## Business Objective/Problem\n","- Tiki là một hệ sinh thái thương mại “all in one”, trong\n","đó có tiki.vn, là một website thương mại điện tử đứng\n","top 2 của Việt Nam, top 6 khu vực Đông Nam Á.\n","- Trên trang này đã triển khai nhiều tiện ích hỗ trợ nâng\n","cao trải nghiệm người dùng và họ muốn xây dựng\n","nhiều tiện ích hơn nữa.\n","- Giả sử công ty này chưa triển khai Recommender\n","System và bạn được yêu cầu triển khai hệ thống này,\n","bạn sẽ làm gì?\n","Đ"]},{"cell_type":"markdown","metadata":{"id":"EkOXP9milfGA"},"source":["## Các kiến thức/ kỹ năng cần để giải quyết\n","vấn đề này:\n","- Hiểu vấn đề\n","- Import các thư viện cần thiết và hiểu cách sử dụng\n","- Đọc dữ liệu (dữ liệu project này được cung cấp)\n","- Thực hiện EDA cơ bản (sử dụng Pandas Profiling\n","Report)\n","- Tiền xử lý dữ liệu: làm sạch, tạo tính năng mới, lựa\n","chọn tính năng cần thiết…"]},{"cell_type":"markdown","metadata":{"id":"9sCrly-AlfDH"},"source":["## Bước 1: Business Understanding\n","- Dựa vào yêu cầu nói trên => xác định vấn đề:\n","  - Chưa có hệ thống Recommendation System\n","  - => Mục tiêu/ vấn đề: Xây dựng Recommendation System\n","  cho một hoặc một số nhóm hàng hóa trên tiki.vn giúp đề\n","  xuất và gợi ý cho người dùng/ khách hàng. => Xây dựng\n","  các mô hình đề xuất:\n","    - Content-based filtering\n","    - Collaborative filtering"]},{"cell_type":"markdown","metadata":{"id":"JT5-vyy1lfA9"},"source":["Bước 2: Data Understanding/ Acquire\n","- Từ mục tiêu/ vấn đề đã xác định: xem xét các dữ\n","liệu cần thiết:\n","  - Dữ liệu được cung cấp sẵn gồm có các tập tin:\n","  ProductRaw.csv, ReviewRaw.csv chứa thông tin sản phẩm,\n","  review và rating cho các sản phẩm thuộc các nhóm hàng\n","  hóa như Mobile_Tablet, TV_Audio, Laptop, Camera,\n","  Accessory"]},{"cell_type":"markdown","metadata":{"id":"5hiCu6DGle9f"},"source":["# Bước 3: Data preparation/ Prepare"]},{"cell_type":"markdown","metadata":{"id":"FePwrk8BSOs9"},"source":["# 5. ALS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrEE-zH5w85y","executionInfo":{"status":"ok","timestamp":1638888626666,"user_tz":-420,"elapsed":209980,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"d1e6443a-5261-47b3-84e3-0b0839f125e5"},"source":["! pip install pandas-profiling==2.7.1\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n","!tar -xvf spark-2.4.0-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","!pip install surprise\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n","import findspark\n","findspark.init()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pandas-profiling==2.7.1\n","  Downloading pandas_profiling-2.7.1-py2.py3-none-any.whl (252 kB)\n","\u001b[K     |████████████████████████████████| 252 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (2.23.0)\n","Collecting visions[type_image_path]==0.4.1\n","  Downloading visions-0.4.1-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 2.5 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (1.4.1)\n","Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (4.62.3)\n","Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (3.2.2)\n","Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (7.6.5)\n","Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (2.11.3)\n","Collecting phik>=0.9.10\n","  Downloading phik-0.12.0-cp37-cp37m-manylinux2010_x86_64.whl (675 kB)\n","\u001b[K     |████████████████████████████████| 675 kB 17.9 MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (1.1.0)\n","Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (1.1.5)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (1.19.5)\n","Collecting confuse>=1.0.0\n","  Downloading confuse-1.7.0-py2.py3-none-any.whl (25 kB)\n","Collecting tangled-up-in-unicode>=0.0.4\n","  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 43.8 MB/s \n","\u001b[?25hRequirement already satisfied: astropy>=4.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (4.3.1)\n","Collecting htmlmin>=0.1.12\n","  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n","Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.7.1) (0.5.0)\n","Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (2.6.3)\n","Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (21.2.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (7.1.2)\n","Collecting imagehash\n","  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n","\u001b[K     |████████████████████████████████| 812 kB 44.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from astropy>=4.0->pandas-profiling==2.7.1) (4.8.2)\n","Requirement already satisfied: pyerfa>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from astropy>=4.0->pandas-profiling==2.7.1) (2.0.0.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from confuse>=1.0.0->pandas-profiling==2.7.1) (3.13)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.0.2)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.10.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (3.5.2)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.5.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.3.5)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.0.18)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (57.4.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.4.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.11.1->pandas-profiling==2.7.1) (2.0.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (3.0.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (2.8.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from missingno>=0.4.2->pandas-profiling==2.7.1) (0.11.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.6.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.9.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.7.1) (2018.9)\n","Collecting scipy>=1.4.1\n","  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n","\u001b[K     |████████████████████████████████| 38.1 MB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2021.10.8)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.12.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.8.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.6.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.7.0)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (1.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->astropy>=4.0->pandas-profiling==2.7.1) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->astropy>=4.0->pandas-profiling==2.7.1) (3.6.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.1.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.3)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.8.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (1.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (21.3)\n","Building wheels for collected packages: htmlmin, imagehash\n","  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=070e6c7b9166c554efb2ff82186568aada05022e6aa4cb13d7c30edbab7d644d\n","  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n","  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295207 sha256=5ec4fcf0b80316fa4fa4ff29c1e3db85ac25f6c8da7c9504d9aece460f6238e3\n","  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n","Successfully built htmlmin imagehash\n","Installing collected packages: tangled-up-in-unicode, scipy, visions, imagehash, phik, htmlmin, confuse, pandas-profiling\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: pandas-profiling\n","    Found existing installation: pandas-profiling 1.4.1\n","    Uninstalling pandas-profiling-1.4.1:\n","      Successfully uninstalled pandas-profiling-1.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed confuse-1.7.0 htmlmin-0.1.12 imagehash-4.2.1 pandas-profiling-2.7.1 phik-0.12.0 scipy-1.7.3 tangled-up-in-unicode-0.2.0 visions-0.4.1\n","spark-2.4.0-bin-hadoop2.7/\n","spark-2.4.0-bin-hadoop2.7/python/\n","spark-2.4.0-bin-hadoop2.7/python/setup.cfg\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/resultiterable.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/python/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/python/pyspark/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/python/pyspark/shell.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/heapq3.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/join.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/version.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/rdd.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/java_gateway.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/find_spark_home.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/_globals.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/worker.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/accumulators.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/feature.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/random.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/classification.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/regression.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/tree.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/common.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/mllib/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/test_broadcast.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/shell.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/feature.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/fpm.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/classification.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/stat.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/tuning.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/regression.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/base.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/clustering.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/linalg/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/common.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/ml/image.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/test_serializers.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/cloudpickle.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/serializers.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/daemon.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/files.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/rddsampler.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/statcounter.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/kafka.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/util.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/flume.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/context.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/streaming/listener.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/taskcontext.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/storagelevel.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/broadcast.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/profiler.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/traceback_utils.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/context.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/status.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/streaming.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/catalog.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/session.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/column.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/functions.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/window.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/udf.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/__init__.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/utils.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/group.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/context.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/conf.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/types.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/tests.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/conf.py\n","spark-2.4.0-bin-hadoop2.7/python/pyspark/shuffle.py\n","spark-2.4.0-bin-hadoop2.7/python/.gitignore\n","spark-2.4.0-bin-hadoop2.7/python/docs/\n","spark-2.4.0-bin-hadoop2.7/python/docs/epytext.py\n","spark-2.4.0-bin-hadoop2.7/python/docs/make2.bat\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.sql.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/make.bat\n","spark-2.4.0-bin-hadoop2.7/python/docs/index.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/_templates/\n","spark-2.4.0-bin-hadoop2.7/python/docs/_templates/layout.html\n","spark-2.4.0-bin-hadoop2.7/python/docs/_static/\n","spark-2.4.0-bin-hadoop2.7/python/docs/_static/pyspark.js\n","spark-2.4.0-bin-hadoop2.7/python/docs/_static/pyspark.css\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.ml.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.streaming.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/conf.py\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.mllib.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/pyspark.rst\n","spark-2.4.0-bin-hadoop2.7/python/docs/Makefile\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/conf/\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n","spark-2.4.0-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n","spark-2.4.0-bin-hadoop2.7/python/run-tests-with-coverage\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/top_level.txt\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/dependency_links.txt\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/requires.txt\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/PKG-INFO\n","spark-2.4.0-bin-hadoop2.7/python/pyspark.egg-info/SOURCES.txt\n","spark-2.4.0-bin-hadoop2.7/python/MANIFEST.in\n","spark-2.4.0-bin-hadoop2.7/python/test_support/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/userlibrary.py\n","spark-2.4.0-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n","spark-2.4.0-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/sub_hello/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/hello/hello.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people_array.json\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/text-test.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people.json\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/ages.csv\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people1.json\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-2.4.0-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n","spark-2.4.0-bin-hadoop2.7/python/run-tests.py\n","spark-2.4.0-bin-hadoop2.7/python/run-tests\n","spark-2.4.0-bin-hadoop2.7/python/.coveragerc\n","spark-2.4.0-bin-hadoop2.7/python/lib/\n","spark-2.4.0-bin-hadoop2.7/python/lib/pyspark.zip\n","spark-2.4.0-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n","spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip\n","spark-2.4.0-bin-hadoop2.7/python/setup.py\n","spark-2.4.0-bin-hadoop2.7/python/README.md\n","spark-2.4.0-bin-hadoop2.7/python/dist/\n","spark-2.4.0-bin-hadoop2.7/python/pylintrc\n","spark-2.4.0-bin-hadoop2.7/conf/\n","spark-2.4.0-bin-hadoop2.7/conf/fairscheduler.xml.template\n","spark-2.4.0-bin-hadoop2.7/conf/spark-defaults.conf.template\n","spark-2.4.0-bin-hadoop2.7/conf/docker.properties.template\n","spark-2.4.0-bin-hadoop2.7/conf/log4j.properties.template\n","spark-2.4.0-bin-hadoop2.7/conf/metrics.properties.template\n","spark-2.4.0-bin-hadoop2.7/conf/slaves.template\n","spark-2.4.0-bin-hadoop2.7/conf/spark-env.sh.template\n","spark-2.4.0-bin-hadoop2.7/licenses/\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-heapq.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-vis.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-spire.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-scala.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-javassist.html\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-janino.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-respond.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-join.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jline.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-jtransforms.html\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n","spark-2.4.0-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n","spark-2.4.0-bin-hadoop2.7/sbin/\n","spark-2.4.0-bin-hadoop2.7/sbin/start-slave.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-history-server.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-slave.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-all.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/spark-daemon.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-master.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/spark-daemons.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/spark-config.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-slaves.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-history-server.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/slaves.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-slaves.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-thriftserver.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-master.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/start-thriftserver.sh\n","spark-2.4.0-bin-hadoop2.7/sbin/stop-all.sh\n","spark-2.4.0-bin-hadoop2.7/kubernetes/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n","spark-2.4.0-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n","spark-2.4.0-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n","spark-2.4.0-bin-hadoop2.7/jars/\n","spark-2.4.0-bin-hadoop2.7/jars/commons-lang3-3.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arrow-format-0.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-jackson_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-jdbc-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-column-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/pyrolite-4.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hppc-0.7.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-jvm-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-guava-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/guice-3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jsp-api-2.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-net-3.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/validation-api-1.1.0.Final.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-ast_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.inject-1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-network-shuffle_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/orc-shims-1.5.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-container-servlet-core-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-compiler-2.11.12.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-graphx_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-media-jaxb-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/antlr4-runtime-4.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-kubernetes_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/okhttp-3.8.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0-tests.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/ST4-4.0.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/eigenbase-properties-1.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-1.7.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-annotations-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/kubernetes-model-2.0.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-tags_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-module-paranamer-2.7.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-server-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-parser-combinators_2.11-1.1.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/snappy-java-1.1.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arrow-memory-0.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hk2-utils-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-repl_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/joda-time-2.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-crypto-1.0.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/aopalliance-1.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/log4j-1.2.17.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xz-1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hk2-locator-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/libthrift-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/chill-java-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/logging-interceptor-3.8.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/opencsv-2.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/lz4-java-1.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-streaming_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/slf4j-log4j12-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/calcite-core-1.2.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/breeze_2.11-0.13.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-bundle-1.6.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-hive-thriftserver_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.inject-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-json-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/aopalliance-repackaged-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-mesos_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/antlr-runtime-3.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/httpcore-4.4.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-graphite-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/netty-3.9.9.Final.jar\n","spark-2.4.0-bin-hadoop2.7/jars/guava-14.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/datanucleus-core-3.2.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/antlr-2.7.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-common-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-lang-2.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/datanucleus-api-jdo-3.2.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-digester-1.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-annotations-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jtransforms-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/snakeyaml-1.15.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-cli-1.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jpam-1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/zookeeper-3.4.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.ws.rs-api-2.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-scalap_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-kvstore_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/avro-1.8.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n","spark-2.4.0-bin-hadoop2.7/jars/paranamer-2.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/RoaringBitmap-0.5.11.jar\n","spark-2.4.0-bin-hadoop2.7/jars/janino-3.0.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stringtemplate-3.2.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n","spark-2.4.0-bin-hadoop2.7/jars/apache-log4j-extras-1.2.17.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xbean-asm6-shaded-4.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/oro-2.0.8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.annotation-api-1.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/chill_2.11-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-mllib_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-exec-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-core_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/okio-1.13.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-databind-2.6.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/netty-all-4.1.17.Final.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-compiler-3.0.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-hadoop-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jul-to-slf4j-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/core-1.1.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-codec-1.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/gson-2.2.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/zstd-jni-1.3.2-2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javolution-5.5.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/univocity-parsers-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n","spark-2.4.0-bin-hadoop2.7/jars/kubernetes-client-3.0.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-common-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/orc-mapreduce-1.5.2-nohive.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jersey-client-2.22.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xercesImpl-2.9.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/machinist_2.11-0.6.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jta-1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/osgi-resource-locator-1.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/datanucleus-rdbms-3.2.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javassist-3.18.1-GA.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spire-macros_2.11-0.13.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/calcite-linq4j-1.2.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jline-2.14.6.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-launcher_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-client-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-metastore-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spire_2.11-0.13.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-core-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/orc-core-1.5.2-nohive.jar\n","spark-2.4.0-bin-hadoop2.7/jars/aircompressor-0.10.jar\n","spark-2.4.0-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-xml_2.11-1.0.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-hive_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-jackson-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-sketch_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-beeline-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-network-common_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-beanutils-core-1.8.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stream-2.7.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-compress-1.8.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/macro-compat_2.11-1.1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/activation-1.1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/breeze-macros_2.11-0.13.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/shapeless_2.11-2.3.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/minlog-1.3.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-sql_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-mllib-local_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hive-cli-1.2.1.spark2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/metrics-core-3.1.5.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-module-scala_2.11-2.6.7.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/automaton-1.11-8.jar\n","spark-2.4.0-bin-hadoop2.7/jars/objenesis-2.5.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/json4s-core_2.11-3.5.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/py4j-0.10.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jetty-6.1.26.jar\n","spark-2.4.0-bin-hadoop2.7/jars/slf4j-api-1.7.16.jar\n","spark-2.4.0-bin-hadoop2.7/jars/commons-io-2.4.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-reflect-2.11.12.jar\n","spark-2.4.0-bin-hadoop2.7/jars/xmlenc-0.52.jar\n","spark-2.4.0-bin-hadoop2.7/jars/spark-yarn_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n","spark-2.4.0-bin-hadoop2.7/jars/ivy-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/scala-library-2.11.12.jar\n","spark-2.4.0-bin-hadoop2.7/jars/snappy-0.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jsr305-1.3.9.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hk2-api-2.4.0-b34.jar\n","spark-2.4.0-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.6.7.jar\n","spark-2.4.0-bin-hadoop2.7/jars/arrow-vector-0.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/flatbuffers-1.2.0-3f79e055.jar\n","spark-2.4.0-bin-hadoop2.7/jars/calcite-avatica-1.2.0-incubating.jar\n","spark-2.4.0-bin-hadoop2.7/jars/generex-1.0.1.jar\n","spark-2.4.0-bin-hadoop2.7/jars/JavaEWAH-0.3.2.jar\n","spark-2.4.0-bin-hadoop2.7/jars/parquet-encoding-1.10.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/javax.servlet-api-3.1.0.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-hdfs-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/jars/hadoop-auth-2.7.3.jar\n","spark-2.4.0-bin-hadoop2.7/bin/\n","spark-2.4.0-bin-hadoop2.7/bin/beeline\n","spark-2.4.0-bin-hadoop2.7/bin/pyspark\n","spark-2.4.0-bin-hadoop2.7/bin/pyspark.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/find-spark-home\n","spark-2.4.0-bin-hadoop2.7/bin/spark-submit2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-class.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/run-example\n","spark-2.4.0-bin-hadoop2.7/bin/sparkR2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-sql2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-submit.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/run-example.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/sparkR.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-class2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-submit\n","spark-2.4.0-bin-hadoop2.7/bin/sparkR\n","spark-2.4.0-bin-hadoop2.7/bin/spark-sql.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/load-spark-env.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/pyspark2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/docker-image-tool.sh\n","spark-2.4.0-bin-hadoop2.7/bin/spark-shell\n","spark-2.4.0-bin-hadoop2.7/bin/find-spark-home.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-shell.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/load-spark-env.sh\n","spark-2.4.0-bin-hadoop2.7/bin/spark-sql\n","spark-2.4.0-bin-hadoop2.7/bin/spark-shell2.cmd\n","spark-2.4.0-bin-hadoop2.7/bin/spark-class\n","spark-2.4.0-bin-hadoop2.7/bin/beeline.cmd\n","spark-2.4.0-bin-hadoop2.7/RELEASE\n","spark-2.4.0-bin-hadoop2.7/R/\n","spark-2.4.0-bin-hadoop2.7/R/lib/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.html\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/sparkr-vignettes.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/doc/index.html\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/R.css\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/vignette.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n","spark-2.4.0-bin-hadoop2.7/R/lib/SparkR/INDEX\n","spark-2.4.0-bin-hadoop2.7/R/lib/sparkr.zip\n","spark-2.4.0-bin-hadoop2.7/yarn/\n","spark-2.4.0-bin-hadoop2.7/yarn/spark-2.4.0-yarn-shuffle.jar\n","spark-2.4.0-bin-hadoop2.7/examples/\n","spark-2.4.0-bin-hadoop2.7/examples/jars/\n","spark-2.4.0-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.4.0.jar\n","spark-2.4.0-bin-hadoop2.7/examples/jars/scopt_2.11-3.7.0.jar\n","spark-2.4.0-bin-hadoop2.7/examples/src/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/als.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/pagerank.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_estimator_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/flume_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/kafka_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/direct_kafka_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/kmeans.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/sort.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/pi.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegression.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RegressionMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LinearRegressionWithSGDExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderEstimatorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRegressionMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLinearRegressionWithSGDExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderEstimatorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/als.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/streaming/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/r/dataframe.R\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.csv\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.avro\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/employees.json\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.json\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/people.txt\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.parquet\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/users.orc\n","spark-2.4.0-bin-hadoop2.7/examples/src/main/resources/user.avsc\n","spark-2.4.0-bin-hadoop2.7/NOTICE\n","spark-2.4.0-bin-hadoop2.7/data/\n","spark-2.4.0-bin-hadoop2.7/data/graphx/\n","spark-2.4.0-bin-hadoop2.7/data/graphx/users.txt\n","spark-2.4.0-bin-hadoop2.7/data/graphx/followers.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/gmm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/origin/license.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/license.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/kmeans_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/pic_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/pagerank_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/als/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/als/test.data\n","spark-2.4.0-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/ridge-data/\n","spark-2.4.0-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n","spark-2.4.0-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n","spark-2.4.0-bin-hadoop2.7/data/streaming/\n","spark-2.4.0-bin-hadoop2.7/data/streaming/AFINN-111.txt\n","spark-2.4.0-bin-hadoop2.7/README.md\n","spark-2.4.0-bin-hadoop2.7/LICENSE\n","Collecting surprise\n","  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n","Collecting scikit-surprise\n","  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n","\u001b[K     |████████████████████████████████| 11.8 MB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.1.0)\n","Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.7.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n","Building wheels for collected packages: scikit-surprise\n","  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619409 sha256=ba07dbccd66e04b327e288128274c2688fd2a0ebf55bd6def9a0e73c468e2577\n","  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n","Successfully built scikit-surprise\n","Installing collected packages: scikit-surprise, surprise\n","Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HiZXpXCkzVFb","executionInfo":{"status":"ok","timestamp":1638888669202,"user_tz":-420,"elapsed":42544,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"33f9955e-a6dd-4503-d36b-bd387bf55583"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBOnZtq8zXaZ","executionInfo":{"status":"ok","timestamp":1638888669203,"user_tz":-420,"elapsed":19,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"2a096e82-05fe-4b4f-ecbb-fbe589abbe41"},"source":["%cd '/content/gdrive/My Drive/LDS0_K271_PhamThiHoa/Project_3'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/LDS0_K271_PhamThiHoa/Project_3\n"]}]},{"cell_type":"code","metadata":{"id":"kb0wqnwyw81z"},"source":["from pyspark.sql import SparkSession\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.feature import StringIndexer\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import *\n","from pyspark.sql.types import FloatType\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4q3OMSMw8sL"},"source":["sc = SparkContext()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W83Vc89vw8pM"},"source":["spark = SparkSession.builder.appName('ALS').getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zswKJSArZo5d"},"source":["# Loads data.\n","products_df = spark.read.csv(\"Data/Products.csv\", \n","                     inferSchema= True,\n","                     header=True,\n","                     sep=',',\n","                     multiLine=True,\n","                     quote=\"\\\"\",\n","                     escape=\"\\\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0ki9e8OZsDx","executionInfo":{"status":"ok","timestamp":1638888680086,"user_tz":-420,"elapsed":1668,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"6f81f353-b93d-4788-d277-4492057db4c7"},"source":["products_df.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+--------------------+--------------------+------+-------+----------+--------+--------------------+--------------------+--------------------+\n","| item_id|                name|         description|rating|  price|list_price|   brand|               group|                 url|               image|\n","+--------+--------------------+--------------------+------+-------+----------+--------+--------------------+--------------------+--------------------+\n","|48102821|Tai nghe Bluetoot...|THÔNG TIN CHI TIẾ...|   4.0|  77000|    300000|     OEM|Thiết Bị Số - Phụ...|https://tai-nghe-...|https://salt.tiki...|\n","|52333193|Tai nghe bluetoot...|THÔNG TIN CHI TIẾ...|   4.5| 132000|    750000|     OEM|Thiết Bị Số - Phụ...|https://tai-nghe-...|https://salt.tiki...|\n","|  299461|Chuột Không Dây L...|THÔNG TIN CHI TIẾ...|   4.8| 299000|    399000|Logitech|Thiết Bị Số - Phụ...|https://chuot-kho...|https://salt.tiki...|\n","|57440329|Loa Bluetooth 5.0...|THÔNG TIN CHI TIẾ...|   4.7| 149000|    350000|   Acome|Thiết Bị Số - Phụ...|https://loa-bluet...|https://salt.tiki...|\n","|38458616|Tai Nghe Bluetoot...|THÔNG TIN CHI TIẾ...|   4.8|5090000|   8500000|   Apple|Thiết Bị Số - Phụ...|https://tai-nghe-...|https://salt.tiki...|\n","+--------+--------------------+--------------------+------+-------+----------+--------+--------------------+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"FiF2iajDw8d0","executionInfo":{"status":"ok","timestamp":1638888681973,"user_tz":-420,"elapsed":1893,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"ea51b27e-069d-420b-8b2f-d8c2f63cdd10"},"source":["reviews = pd.read_csv('Data/Reviews.csv',lineterminator='\\n')\n","reviews.head()                  "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>product_id</th>\n","      <th>name</th>\n","      <th>rating</th>\n","      <th>title</th>\n","      <th>content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>709310</td>\n","      <td>10001012</td>\n","      <td>Lân Nguyễn Hoàng</td>\n","      <td>3</td>\n","      <td>Ko dùng đc thẻ nhớ</td>\n","      <td>Lúcđầu quên thông tin nên dùng 512gb thì ko đc...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10701688</td>\n","      <td>10001012</td>\n","      <td>Nguyễn Khánh Hòa</td>\n","      <td>5</td>\n","      <td>Cực kì hài lòng</td>\n","      <td>Tiki giao hàng nhanh. Sản phẩm đúng như mô tả,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11763074</td>\n","      <td>10001012</td>\n","      <td>Toàn Phạm Khánh</td>\n","      <td>5</td>\n","      <td>Cực kì hài lòng</td>\n","      <td>chất lượng camera rõ nét, chống mưa nắng tuyệt...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9909549</td>\n","      <td>10001012</td>\n","      <td>Nguyen Quang Minh</td>\n","      <td>5</td>\n","      <td>Rất hài lòng</td>\n","      <td>Hàng được đóng gói cẩn thận, giao hàng nhanh ,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1827148</td>\n","      <td>10001012</td>\n","      <td>Phạm Bá Đức</td>\n","      <td>5</td>\n","      <td>Cực kì hài lòng</td>\n","      <td>dễ cài đặt, chất lượng tốt, chế độ xem hồng ng...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id  ...                                            content\n","0       709310  ...  Lúcđầu quên thông tin nên dùng 512gb thì ko đc...\n","1     10701688  ...  Tiki giao hàng nhanh. Sản phẩm đúng như mô tả,...\n","2     11763074  ...  chất lượng camera rõ nét, chống mưa nắng tuyệt...\n","3      9909549  ...  Hàng được đóng gói cẩn thận, giao hàng nhanh ,...\n","4      1827148  ...  dễ cài đặt, chất lượng tốt, chế độ xem hồng ng...\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vN1NeiIoetje","executionInfo":{"status":"ok","timestamp":1638888682975,"user_tz":-420,"elapsed":1031,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"d18ac064-f02f-411a-898b-1853063348a9"},"source":["reviews.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 361090 entries, 0 to 361089\n","Data columns (total 6 columns):\n"," #   Column       Non-Null Count   Dtype \n","---  ------       --------------   ----- \n"," 0   customer_id  361090 non-null  int64 \n"," 1   product_id   361090 non-null  int64 \n"," 2   name         360662 non-null  object\n"," 3   rating       361090 non-null  int64 \n"," 4   title        361062 non-null  object\n"," 5   content      165053 non-null  object\n","dtypes: int64(3), object(3)\n","memory usage: 16.5+ MB\n"]}]},{"cell_type":"code","metadata":{"id":"lTRgW39HetJk"},"source":["schema = StructType([StructField( 'customer_id', IntegerType(), True),StructField( 'product_id', IntegerType(), True),StructField('name', StringType(), True),StructField( 'rating', IntegerType(), True),StructField( 'title', StringType(), True),StructField('content', StringType(), True)])\n","reviews = spark.createDataFrame(data=reviews, schema= schema)     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0bfXRYvRqtl","executionInfo":{"status":"ok","timestamp":1638888687846,"user_tz":-420,"elapsed":1099,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"2d7b9350-a1d1-4808-a98d-d401ffb5f79a"},"source":["reviews.show(3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+----------+----------------+------+------------------+--------------------+\n","|customer_id|product_id|            name|rating|             title|             content|\n","+-----------+----------+----------------+------+------------------+--------------------+\n","|     709310|  10001012|Lân Nguyễn Hoàng|     3|Ko dùng đc thẻ nhớ|Lúcđầu quên thông...|\n","|   10701688|  10001012|Nguyễn Khánh Hòa|     5|   Cực kì hài lòng|Tiki giao hàng nh...|\n","|   11763074|  10001012| Toàn Phạm Khánh|     5|   Cực kì hài lòng|chất lượng camera...|\n","+-----------+----------+----------------+------+------------------+--------------------+\n","only showing top 3 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8a_nZX-SCP1","executionInfo":{"status":"ok","timestamp":1638888687847,"user_tz":-420,"elapsed":16,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"0c3ca8a8-1114-4b80-c13a-77c42f212454"},"source":["reviews.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['customer_id', 'product_id', 'name', 'rating', 'title', 'content']"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Osgrf5LEST9Q"},"source":["- Đây là bài toán Filtering \n","chỉ lấy dữ liệu 3 cột để phân tích\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDpObZthSGCx","executionInfo":{"status":"ok","timestamp":1638888687848,"user_tz":-420,"elapsed":12,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"55a11c0a-0dcf-4c2f-dcf4-290749c37e3b"},"source":["# Chỉ lấy dữ liệu ở 3 cột ['product_id','rating','customer_id']\n","data = reviews.select(['product_id','rating','customer_id'])\n","data.show(3)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------+-----------+\n","|product_id|rating|customer_id|\n","+----------+------+-----------+\n","|  10001012|     3|     709310|\n","|  10001012|     5|   10701688|\n","|  10001012|     5|   11763074|\n","+----------+------+-----------+\n","only showing top 3 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtOVpcqXSqjk","executionInfo":{"status":"ok","timestamp":1638888692632,"user_tz":-420,"elapsed":4792,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"180c894f-82d3-4df4-94af-ff6cdd5f9fef"},"source":["data.describe().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+--------------------+------------------+-----------------+\n","|summary|          product_id|            rating|      customer_id|\n","+-------+--------------------+------------------+-----------------+\n","|  count|              361090|            361090|           361090|\n","|   mean|2.4406563573685233E7| 4.475136392589105|9179677.248489296|\n","| stddev| 2.378465728570825E7|1.0166716679634726|6307971.007714791|\n","|    min|               54665|                 1|               10|\n","|    max|            81964004|                 5|         21013443|\n","+-------+--------------------+------------------+-----------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKFu735BSvXR","executionInfo":{"status":"ok","timestamp":1638888692633,"user_tz":-420,"elapsed":16,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"c132b9bb-6ba9-4adb-f5c5-38777fe2f060"},"source":["data.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- product_id: integer (nullable = true)\n"," |-- rating: integer (nullable = true)\n"," |-- customer_id: integer (nullable = true)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"bAFXzDrXWIjw"},"source":["# Distinct users and products\n","users = reviews.select('customer_id').distinct().count()\n","products = reviews.select('product_id').distinct().count()\n","numerator = reviews.count()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"l2DV4z2xclVt","executionInfo":{"status":"ok","timestamp":1638888702352,"user_tz":-420,"elapsed":46,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"5c3d0746-298a-482d-d72c-2d6850d8f0ce"},"source":["display(numerator, users, products)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["361090"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["251149"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["4214"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GkrY56fcpC6","executionInfo":{"status":"ok","timestamp":1638888702353,"user_tz":-420,"elapsed":41,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"d6dfdf28-92cf-4ea4-eaac-0c7df93ff512"},"source":["# Number of raings matrix could contain if no empty cells\n","denominator = users * products\n","denominator"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1058341886"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kxaWLY4zcrXK","executionInfo":{"status":"ok","timestamp":1638888702354,"user_tz":-420,"elapsed":35,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"47e653e5-dedb-4350-e279-6b608860c949"},"source":["# Calculating spaarsity\n","sparsity = 1 - (numerator*1.0/denominator)\n","print('Sparsity: '), sparsity"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sparsity: \n"]},{"output_type":"execute_result","data":{"text/plain":["(None, 0.999658815355627)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xisZkBpod5Cv","executionInfo":{"status":"ok","timestamp":1638888705138,"user_tz":-420,"elapsed":2814,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"daa9f1b2-1273-4649-b6db-c380b6828433"},"source":["# Check Null - Nan\n","data.select([count(when(isnan(c)|isnull(c),c)).alias (c) for c in data.columns]).show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------+-----------+\n","|product_id|rating|customer_id|\n","+----------+------+-----------+\n","|         0|     0|          0|\n","+----------+------+-----------+\n","\n"]}]},{"cell_type":"code","metadata":{"id":"n6qjpsuzd2-p"},"source":["# Chia tập dữ liệu thành train và test\n","(training, test) = data.randomSplit([0.8,0.2])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xBbh71U4c0Mk"},"source":["# Model\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOq6T1krcu76","executionInfo":{"status":"ok","timestamp":1638888707092,"user_tz":-420,"elapsed":1960,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"bb826bf4-8d7e-41fb-abb6-3a9aadfe0437"},"source":["data.describe().show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+--------------------+------------------+-----------------+\n","|summary|          product_id|            rating|      customer_id|\n","+-------+--------------------+------------------+-----------------+\n","|  count|              361090|            361090|           361090|\n","|   mean|2.4406563573685233E7| 4.475136392589105|9179677.248489296|\n","| stddev| 2.378465728570825E7|1.0166716679634726|6307971.007714791|\n","|    min|               54665|                 1|               10|\n","|    max|            81964004|                 5|         21013443|\n","+-------+--------------------+------------------+-----------------+\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i_5miKCVefR7","executionInfo":{"status":"ok","timestamp":1638888707093,"user_tz":-420,"elapsed":10,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"06b4951c-9b93-40ea-b8a0-e1cb193b2157"},"source":["data.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- product_id: integer (nullable = true)\n"," |-- rating: integer (nullable = true)\n"," |-- customer_id: integer (nullable = true)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"b5X-SF2TdkTd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638888731304,"user_tz":-420,"elapsed":24217,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"04796730-9290-4378-dd7e-1b9208a634c5"},"source":["from time import time\n","t0 = time()\n","als = ALS(maxIter=5, regParam=0.09,rank=25, userCol='customer_id', itemCol= 'product_id',ratingCol='rating', coldStartStrategy='drop', nonnegative= True)\n","model = als.fit(training)\n","t = time() - t0\n","t"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["24.23385453224182"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"GKve7_GxfLxx"},"source":["# Đánh giá kết quả"]},{"cell_type":"code","metadata":{"id":"W77MBRJTeI72"},"source":["# Evalute the model by computing the RMSE on the test data\n","predictions = model.transform(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWjvVzg1fRBm","executionInfo":{"status":"ok","timestamp":1638888743665,"user_tz":-420,"elapsed":12367,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"04bb5f87-b6dc-4515-d5be-1a6b8dc6f3cf"},"source":["predictions.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+------+-----------+----------+\n","|product_id|rating|customer_id|prediction|\n","+----------+------+-----------+----------+\n","|    605223|     5|    8591725| 2.5919783|\n","|   2069769|     5|    7005222| 2.2801661|\n","|   2069769|     1|   14596766| 3.8261404|\n","|   2069769|     5|   13931579| 5.2268744|\n","|   2086067|     5|   11296538| 5.2807603|\n","+----------+------+-----------+----------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"vtNKG23efS2n"},"source":["evaluator = RegressionEvaluator(metricName='rmse',\n","                               labelCol='rating',\n","                               predictionCol='prediction')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fV9IUwnLfV59","executionInfo":{"status":"ok","timestamp":1638888758337,"user_tz":-420,"elapsed":14689,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"3fc177b8-aa23-47ba-abe1-8941c02a658c"},"source":["rmse = evaluator.evaluate(predictions)\n","print('Root_mean_squar_error:', rmse)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Root_mean_squar_error: 2.116825497610228\n"]}]},{"cell_type":"markdown","metadata":{"id":"fLCCm2qnfjbp"},"source":["rmse = 2.12 > std = 1.16\n","Thử tìm kiếm một model khác để giảm rmse xuống nếu có thể\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWoSFjQNffJQ","executionInfo":{"status":"ok","timestamp":1638888821795,"user_tz":-420,"elapsed":63477,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"6f908f61-0f50-4fe4-b5ed-b62e4b70bdad"},"source":["t0 = time()\n","als_t = ALS(maxIter=25, regParam=0.1,rank= 25,  userCol='customer_id', itemCol= 'product_id',ratingCol='rating', coldStartStrategy='drop', nonnegative= True)\n","model_t = als_t.fit(training)\n","time() - t0"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["63.359699964523315"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"ddlcJC-afvJI"},"source":["predictions_t = model_t.transform(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cji-CE9mf4rs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638888835043,"user_tz":-420,"elapsed":13256,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"c262b588-9baa-4508-cfbe-798667d0f395"},"source":["rmse_t = evaluator.evaluate(predictions_t)\n","print('Root_mean_squar_error:', rmse_t)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Root_mean_squar_error: 1.1986054346100823\n"]}]},{"cell_type":"markdown","metadata":{"id":"oOp06N19f-K1"},"source":["- rmse giảm xuống = 1.19 ~ std = 1.16 => chọn model_t"]},{"cell_type":"code","metadata":{"id":"NV48VzxFf6ss"},"source":["# Đưa ra đề xuất cho tất cả các user\n","# Get 10 recommendations\n","user_recs = model_t.recommendForAllUsers(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycpGfA4egEv0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638888835561,"user_tz":-420,"elapsed":8,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"4b60e80c-0328-4614-9bed-93782764b126"},"source":["user_recs.printSchema()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- customer_id: integer (nullable = false)\n"," |-- recommendations: array (nullable = true)\n"," |    |-- element: struct (containsNull = true)\n"," |    |    |-- product_id: integer (nullable = true)\n"," |    |    |-- rating: float (nullable = true)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"FmrCb2lMgKKa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638888947616,"user_tz":-420,"elapsed":112060,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"fe697b8f-a75e-4d69-c6a9-bc1c8d6898cf"},"source":["user_recs.show(3, False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|customer_id|recommendations                                                                                                                                                                                                                |\n","+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|471        |[[66251373, 5.277201], [10690707, 5.0774937], [71293311, 5.071312], [72323554, 4.996207], [50692303, 4.9147205], [55897, 4.8897676], [75983219, 4.8622026], [491431, 4.8546195], [742272, 4.847637], [50560429, 4.847374]]     |\n","|833        |[[71293311, 5.092226], [44227610, 4.891177], [66251373, 4.8573303], [72323554, 4.853566], [48520298, 4.845986], [76732229, 4.8436227], [68527587, 4.83509], [54023388, 4.808348], [45075149, 4.7963247], [67106618, 4.7847924]]|\n","|7993       |[[25965194, 4.887198], [65439708, 4.8427987], [19351442, 4.83684], [76358835, 4.7235246], [3281929, 4.7152805], [66251373, 4.697518], [69149307, 4.6811056], [10690707, 4.679069], [50421557, 4.6658034], [6479167, 4.6621985]]|\n","+-----------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 3 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"cN33Fkl6gLV_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638889052542,"user_tz":-420,"elapsed":104934,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"723105d4-d0f0-4295-abbc-82aa9e84682b"},"source":["for user in user_recs.head(3):\n","    print(user)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Row(customer_id=471, recommendations=[Row(product_id=66251373, rating=5.277201175689697), Row(product_id=10690707, rating=5.077493667602539), Row(product_id=71293311, rating=5.071311950683594), Row(product_id=72323554, rating=4.996207237243652), Row(product_id=50692303, rating=4.91472053527832), Row(product_id=55897, rating=4.889767646789551), Row(product_id=75983219, rating=4.8622026443481445), Row(product_id=491431, rating=4.85461950302124), Row(product_id=742272, rating=4.847637176513672), Row(product_id=50560429, rating=4.847373962402344)])\n","Row(customer_id=833, recommendations=[Row(product_id=71293311, rating=5.092226028442383), Row(product_id=44227610, rating=4.891177177429199), Row(product_id=66251373, rating=4.857330322265625), Row(product_id=72323554, rating=4.8535661697387695), Row(product_id=48520298, rating=4.8459858894348145), Row(product_id=76732229, rating=4.84362268447876), Row(product_id=68527587, rating=4.835090160369873), Row(product_id=54023388, rating=4.808348178863525), Row(product_id=45075149, rating=4.796324729919434), Row(product_id=67106618, rating=4.784792423248291)])\n","Row(customer_id=7993, recommendations=[Row(product_id=25965194, rating=4.887197971343994), Row(product_id=65439708, rating=4.842798709869385), Row(product_id=19351442, rating=4.8368401527404785), Row(product_id=76358835, rating=4.723524570465088), Row(product_id=3281929, rating=4.715280532836914), Row(product_id=66251373, rating=4.6975178718566895), Row(product_id=69149307, rating=4.681105613708496), Row(product_id=10690707, rating=4.6790690422058105), Row(product_id=50421557, rating=4.6658034324646), Row(product_id=6479167, rating=4.662198543548584)])\n"]}]},{"cell_type":"code","metadata":{"id":"qj1KQaMUgORk","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638889190819,"user_tz":-420,"elapsed":138282,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"ab4b3027-9a1c-45f0-ee8a-fc2f3a1cb480"},"source":["recs = user_recs.toPandas()\n","recs.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>recommendations</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471</td>\n","      <td>[(66251373, 5.277201175689697), (10690707, 5.0...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>833</td>\n","      <td>[(71293311, 5.092226028442383), (44227610, 4.8...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7993</td>\n","      <td>[(25965194, 4.887197971343994), (65439708, 4.8...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9427</td>\n","      <td>[(71293311, 1.0456827878952026), (40351876, 1....</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17420</td>\n","      <td>[(71293311, 5.492371559143066), (66251373, 5.4...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id                                    recommendations\n","0          471  [(66251373, 5.277201175689697), (10690707, 5.0...\n","1          833  [(71293311, 5.092226028442383), (44227610, 4.8...\n","2         7993  [(25965194, 4.887197971343994), (65439708, 4.8...\n","3         9427  [(71293311, 1.0456827878952026), (40351876, 1....\n","4        17420  [(71293311, 5.492371559143066), (66251373, 5.4..."]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"4LQs3Us5gVcI"},"source":["nrecs = recs['recommendations'].apply(pd.Series).merge(recs, right_index= True, left_index= True).drop(['recommendations'],axis = 1).melt(id_vars = ['customer_id'], value_name = 'recommendations').drop('variable', axis = 1).dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zqs298jPgRCt","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638889260006,"user_tz":-420,"elapsed":50,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"7abdb698-b312-444a-e5ef-990ddb2377d5"},"source":["nrecs.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>recommendations</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471</td>\n","      <td>(66251373, 5.277201175689697)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>833</td>\n","      <td>(71293311, 5.092226028442383)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7993</td>\n","      <td>(25965194, 4.887197971343994)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9427</td>\n","      <td>(71293311, 1.0456827878952026)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17420</td>\n","      <td>(71293311, 5.492371559143066)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id                 recommendations\n","0          471   (66251373, 5.277201175689697)\n","1          833   (71293311, 5.092226028442383)\n","2         7993   (25965194, 4.887197971343994)\n","3         9427  (71293311, 1.0456827878952026)\n","4        17420   (71293311, 5.492371559143066)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"MNjg5eDVgYpS","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638889260517,"user_tz":-420,"elapsed":544,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"0cb309a2-ef1c-4e0c-e436-9a3483b39519"},"source":["nrecs = nrecs.sort_values('customer_id')\n","nrecs.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>recommendations</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>340164</th>\n","      <td>10</td>\n","      <td>(416911, 3.911929130554199)</td>\n","    </tr>\n","    <tr>\n","      <th>2031252</th>\n","      <td>10</td>\n","      <td>(71938164, 3.795532464981079)</td>\n","    </tr>\n","    <tr>\n","      <th>1185708</th>\n","      <td>10</td>\n","      <td>(71293311, 3.843348503112793)</td>\n","    </tr>\n","    <tr>\n","      <th>1608480</th>\n","      <td>10</td>\n","      <td>(24558526, 3.8100805282592773)</td>\n","    </tr>\n","    <tr>\n","      <th>551550</th>\n","      <td>10</td>\n","      <td>(48520298, 3.8965165615081787)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         customer_id                 recommendations\n","340164            10     (416911, 3.911929130554199)\n","2031252           10   (71938164, 3.795532464981079)\n","1185708           10   (71293311, 3.843348503112793)\n","1608480           10  (24558526, 3.8100805282592773)\n","551550            10  (48520298, 3.8965165615081787)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"iMzwcj02gaqC"},"source":["nrecs = pd.concat([nrecs['recommendations'].apply(pd.Series), nrecs['customer_id']],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pv1jx1sVgfgH"},"source":["nrecs.columns = ['product_id', 'rating', 'customer_id']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PyVNPdBNgmFq","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638889854593,"user_tz":-420,"elapsed":42,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"a301d6ed-fd3c-40c8-823a-9ec85f3ef7a1"},"source":["nrecs.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>rating</th>\n","      <th>customer_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>340164</th>\n","      <td>416911.0</td>\n","      <td>3.911929</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>2031252</th>\n","      <td>71938164.0</td>\n","      <td>3.795532</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1185708</th>\n","      <td>71293311.0</td>\n","      <td>3.843349</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1608480</th>\n","      <td>24558526.0</td>\n","      <td>3.810081</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>551550</th>\n","      <td>48520298.0</td>\n","      <td>3.896517</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         product_id    rating  customer_id\n","340164     416911.0  3.911929           10\n","2031252  71938164.0  3.795532           10\n","1185708  71293311.0  3.843349           10\n","1608480  24558526.0  3.810081           10\n","551550   48520298.0  3.896517           10"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"flquTFzIgq10"},"source":["md = data.toPandas()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tUkCrW1b21k8","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1638889858455,"user_tz":-420,"elapsed":21,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"80ff5a99-0ae1-4ab1-9fbc-9720e42dfd21"},"source":["md"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>rating</th>\n","      <th>customer_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10001012</td>\n","      <td>3</td>\n","      <td>709310</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10001012</td>\n","      <td>5</td>\n","      <td>10701688</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10001012</td>\n","      <td>5</td>\n","      <td>11763074</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10001012</td>\n","      <td>5</td>\n","      <td>9909549</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10001012</td>\n","      <td>5</td>\n","      <td>1827148</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>361085</th>\n","      <td>9996258</td>\n","      <td>5</td>\n","      <td>16820553</td>\n","    </tr>\n","    <tr>\n","      <th>361086</th>\n","      <td>9996258</td>\n","      <td>5</td>\n","      <td>5888640</td>\n","    </tr>\n","    <tr>\n","      <th>361087</th>\n","      <td>9996258</td>\n","      <td>5</td>\n","      <td>12246414</td>\n","    </tr>\n","    <tr>\n","      <th>361088</th>\n","      <td>9996258</td>\n","      <td>5</td>\n","      <td>14309619</td>\n","    </tr>\n","    <tr>\n","      <th>361089</th>\n","      <td>9996258</td>\n","      <td>5</td>\n","      <td>7948382</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>361090 rows × 3 columns</p>\n","</div>"],"text/plain":["        product_id  rating  customer_id\n","0         10001012       3       709310\n","1         10001012       5     10701688\n","2         10001012       5     11763074\n","3         10001012       5      9909549\n","4         10001012       5      1827148\n","...            ...     ...          ...\n","361085     9996258       5     16820553\n","361086     9996258       5      5888640\n","361087     9996258       5     12246414\n","361088     9996258       5     14309619\n","361089     9996258       5      7948382\n","\n","[361090 rows x 3 columns]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"xzBlWSpAgz_T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638889859768,"user_tz":-420,"elapsed":1330,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"142f45f5-8953-46eb-b7ba-d140b29083cd"},"source":["nrecs = nrecs.sort_values('customer_id')\n","nrecs.reset_index(drop=True, inplace= True)\n","new = nrecs[['customer_id','product_id','rating']]\n","new['recommendations'] = list(zip(new.product_id, new.rating))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n"]}]},{"cell_type":"code","metadata":{"id":"pcy2_6Bvgzyh","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638889859773,"user_tz":-420,"elapsed":21,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"4c6c18a8-c412-429b-ad9f-3100ff1d3f3c"},"source":["new.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>product_id</th>\n","      <th>rating</th>\n","      <th>recommendations</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10</td>\n","      <td>416911.0</td>\n","      <td>3.911929</td>\n","      <td>(416911.0, 3.911929130554199)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10</td>\n","      <td>71938164.0</td>\n","      <td>3.795532</td>\n","      <td>(71938164.0, 3.795532464981079)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10</td>\n","      <td>71293311.0</td>\n","      <td>3.843349</td>\n","      <td>(71293311.0, 3.843348503112793)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10</td>\n","      <td>24558526.0</td>\n","      <td>3.810081</td>\n","      <td>(24558526.0, 3.8100805282592773)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>48520298.0</td>\n","      <td>3.896517</td>\n","      <td>(48520298.0, 3.8965165615081787)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id  product_id    rating                   recommendations\n","0           10    416911.0  3.911929     (416911.0, 3.911929130554199)\n","1           10  71938164.0  3.795532   (71938164.0, 3.795532464981079)\n","2           10  71293311.0  3.843349   (71293311.0, 3.843348503112793)\n","3           10  24558526.0  3.810081  (24558526.0, 3.8100805282592773)\n","4           10  48520298.0  3.896517  (48520298.0, 3.8965165615081787)"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"mrK0OLOyhFo_"},"source":["res = new[['customer_id','recommendations']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K4k5PdKFhJJC","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638889868028,"user_tz":-420,"elapsed":7086,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"8e5b09e8-7f2b-4c4c-f1cf-26b046b4384f"},"source":["res_new = res['recommendations'].groupby([res['customer_id']]).apply(list).reset_index()\n","res_new.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customer_id</th>\n","      <th>recommendations</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10</td>\n","      <td>[(416911.0, 3.911929130554199), (71938164.0, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>27</td>\n","      <td>[(19395453.0, 5.037433624267578), (74227763.0,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>[(76732229.0, 4.828741550445557), (40351876.0,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>36</td>\n","      <td>[(10690707.0, 5.307761192321777), (74274442.0,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50</td>\n","      <td>[(66251373.0, 4.043923854827881), (48520298.0,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   customer_id                                    recommendations\n","0           10  [(416911.0, 3.911929130554199), (71938164.0, 3...\n","1           27  [(19395453.0, 5.037433624267578), (74227763.0,...\n","2           28  [(76732229.0, 4.828741550445557), (40351876.0,...\n","3           36  [(10690707.0, 5.307761192321777), (74274442.0,...\n","4           50  [(66251373.0, 4.043923854827881), (48520298.0,..."]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"yap-C_GohNT9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638889868029,"user_tz":-420,"elapsed":12,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"2fe989d3-bb91-4563-d1e1-cceede0966de"},"source":["res_new.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['customer_id', 'recommendations'], dtype='object')"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"fKpQhZbAhPxd"},"source":["final_recs = spark.createDataFrame(res_new, schema=['customer_id', 'recommendations']) # Lưu lại dữ liệu này"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIOJThr2hSLY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638889884727,"user_tz":-420,"elapsed":3038,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"0f6af5ac-5842-47fb-aba2-b2a03c82ee92"},"source":["final_recs.count()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["211386"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"44OE-yhh7h0L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638889884728,"user_tz":-420,"elapsed":10,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"693ae8ce-b76f-4075-8980-7389660afae0"},"source":["final_recs.show(5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+--------------------+\n","|customer_id|     recommendations|\n","+-----------+--------------------+\n","|         10|[[416911.0, 3.911...|\n","|         27|[[1.9395453E7, 5....|\n","|         28|[[7.6732229E7, 4....|\n","|         36|[[1.0690707E7, 5....|\n","|         50|[[6.6251373E7, 4....|\n","+-----------+--------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"mvlmgnO6hU-x"},"source":["# Make recommendations to some users:"]},{"cell_type":"code","metadata":{"id":"2LTCmK5FR44d"},"source":["def recs(userID, score):\n","  print('Recomend for userID = ',userID,'\\n')\n","  result = final_recs.filter(final_recs['customer_id'] == userID)\n","  result = result.select(result['customer_id'], explode(result['recommendations']))\n","\n","  result = result.withColumn('product_id',result.col.getField('_1'))\\\n","              .withColumn('rating', result.col.getField('_2').cast(FloatType()))\n","  products_id_name = products_df.withColumn('product_id', products_df.item_id).select(['name','product_id'])\n","  result = result.join(products_id_name, on= ['product_id'], how='left_outer')\n","  result.filter(result['rating'] > score ).show(truncate = False)\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVS24q8aUlct","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638889888908,"user_tz":-420,"elapsed":4186,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"a5de92c0-4577-4730-e538-e6c3ef71e443"},"source":["userID = 10\n","score = 3\n","result = recs(userID, score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recomend for userID =  10 \n","\n","+-----------+-----------+---------------------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|product_id |customer_id|col                              |rating   |name                                                                                                                                                                                  |\n","+-----------+-----------+---------------------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|416911.0   |10         |[416911.0, 3.911929130554199]    |3.9119291|TP-Link  TL-WN823N - USB Wifi chuẩn N tốc độ 300Mbps - Hàng Chính Hãng                                                                                                                |\n","|7.1938164E7|10         |[7.1938164E7, 3.795532464981079] |3.7955325|Ốp Lưng Chống Sốc Trong Suốt Dành Cho iPhone 11/ 11 Pro/ 11 Pro Max/ 12 Mini/ 12 / 12 Pro/ 12 Pro Max- Hàng Chính Hãng                                                                |\n","|7.1293311E7|10         |[7.1293311E7, 3.843348503112793] |3.8433485|Trọn bộ Camera Ip Wifi Ezviz Cube C1C Full HD 1080P Và Thẻ Nhớ HIKVISION 32GB - Hàng Chính Hãng                                                                                       |\n","|2.4558526E7|10         |[2.4558526E7, 3.8100805282592773]|3.8100805|Ống kính Meike 25mm F1.8 cho máy ảnh mirroless Sony, Fuji, Canon lấy nét thủ công- Hàng nhập khẩu                                                                                     |\n","|4.8520298E7|10         |[4.8520298E7, 3.8965165615081787]|3.8965166|Cassette-Máy CD xách tay JSL RC-EZ57B (Hàng nhập khẩu)                                                                                                                                |\n","|764581.0   |10         |[764581.0, 3.7986817359924316]   |3.7986817|Máy In Laser Đa Năng Brother MFC-L2701DW - Hàng Chính Hãng                                                                                                                            |\n","|7.3476077E7|10         |[7.3476077E7, 3.888731002807617] |3.888731 |Camera IP Wifi IMOU IPC A22EP chuẩn 1080P Xoay 360 độ -  hàng chính hãng                                                                                                              |\n","|6.6251373E7|10         |[6.6251373E7, 4.176393032073975] |4.176393 |Flycam Bugs 20 EIS Gimbal 1 trục + chống rung điện tử - Hàng chính hãng                                                                                                               |\n","|7.5983219E7|10         |[7.5983219E7, 3.813450813293457] |3.8134508|Màn Hình Thông Minh Smart Monitor Samsung LS32AM500NEXXV 32inch/Full HD (1920x1080) 8ms/60Hz/VA/Tích Hợp Loa/Hệ Điều Hành Tizen - Hàng Chính Hãng                                     |\n","|6.7985251E7|10         |[6.7985251E7, 3.8610951900482178]|3.8610952|Camera Ip Giám Sát An Ninh Trong Nhà CC2020, 2.0Mpx 1920x1080P FULL HD, Xoay Theo Chuyển Động, Hú Báo Động, Dùng Cho Điện Thoại, Máy Tính, Smart TV, Dùng APP CARECAM PRO - Chính Hãng|\n","+-----------+-----------+---------------------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"id":"kEzSiznodaeA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638889892436,"user_tz":-420,"elapsed":3549,"user":{"displayName":"Hòa Phạm","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhT95mQGKGhA7vULnX1jX6MDmtP-vM9weqD_QHDIQ=s64","userId":"01113175758328587995"}},"outputId":"c8a59663-e310-4a4a-e4fc-39ae03444327"},"source":["userID = 27\n","score = 4.5\n","result = recs(userID, score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recomend for userID =  27 \n","\n","+-----------+-----------+---------------------------------+---------+-----------------------------------------------------------------------------------------------+\n","|product_id |customer_id|col                              |rating   |name                                                                                           |\n","+-----------+-----------+---------------------------------+---------+-----------------------------------------------------------------------------------------------+\n","|1.9395453E7|27         |[1.9395453E7, 5.037433624267578] |5.0374336|MÁY RỬA CHÉN BOSCH HMH.SMS63L08EA -HÀNG CHÍNH HÃNG                                          |\n","|7.4227763E7|27         |[7.4227763E7, 5.099873065948486] |5.099873 |Smart Tivi Casper Full HD 43 inch 43FG5200                                                     |\n","|7.6310232E7|27         |[7.6310232E7, 5.077657222747803] |5.077657 |Đồng Hồ Thông Minh Theo Dõi Vận Động Theo Dõi Sức Khỏe Huami Amazfit GTR 2 - Hàng Chính Hãng   |\n","|7.1293311E7|27         |[7.1293311E7, 5.51911735534668]  |5.5191174|Trọn bộ Camera Ip Wifi Ezviz Cube C1C Full HD 1080P Và Thẻ Nhớ HIKVISION 32GB - Hàng Chính Hãng|\n","|1.418622E7 |27         |[1.418622E7, 5.046157360076904]  |5.0461574|Máy đếm tiền SCounter ZJ-6100C - Hàng Chính Hãng                                               |\n","|4.0351876E7|27         |[4.0351876E7, 5.1032633781433105]|5.1032634|Điện thoại di động GSM Vtel V1 - Hàng chính hãng                                               |\n","|2080951.0  |27         |[2080951.0, 5.12013578414917]    |5.120136 |Tủ lạnh Samsung Inverter 360 lít RT35K5982BS/SV                                                |\n","|6.6251373E7|27         |[6.6251373E7, 5.432518482208252] |5.4325185|Flycam Bugs 20 EIS Gimbal 1 trục + chống rung điện tử - Hàng chính hãng                        |\n","|4.8520298E7|27         |[4.8520298E7, 5.145906448364258] |5.1459064|Cassette-Máy CD xách tay JSL RC-EZ57B (Hàng nhập khẩu)                                         |\n","|7.4558974E7|27         |[7.4558974E7, 5.069265842437744] |5.069266 |iPad Air 10.5 Wi-Fi 256GB New 2019 - Hàng Chính Hãng                                           |\n","+-----------+-----------+---------------------------------+---------+-----------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","metadata":{"id":"OfTcMpEKhwPW"},"source":["# Lưu model\n","model_t.save('Results/ALS/Model_ALS')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOkDHJeUhxvX"},"source":["# Lưu dữ liệu\n","final_recs.write.parquet('Results/ALS/ALS', mode = 'overwrite')"],"execution_count":null,"outputs":[]}]}